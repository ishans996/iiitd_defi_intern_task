{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "98b75e30",
   "metadata": {},
   "source": [
    "## [TODO]\n",
    "\n",
    "- Dropout everywhere\n",
    "- Should glove embeddings be updated?\n",
    "- Dealing with unknown tokens\n",
    "- You and stocknet-code have included y_T in calculation in ATA, while paper equations have not. Think about it\n",
    "- Correct y_size to 2 from 1 because two classes *aye*, *no*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ece8c5c",
   "metadata": {},
   "source": [
    "# Creating the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "256c1743",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ishans996/myProjects/rawnit_sawhney_defi_task/venv/lib/python3.8/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch; torch.manual_seed(0)\n",
    "import torch.nn as nn\n",
    "import torch.distributions as ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "81641800",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c53758be",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "578fba25",
   "metadata": {},
   "outputs": [],
   "source": [
    "word_embed_size = 100\n",
    "embedder_hidden_size = 100\n",
    "gru_num_layers = 1\n",
    "window_size = 4\n",
    "\n",
    "dropout_vmd_in = 0.3\n",
    "vmd_hidden_size = 150\n",
    "g_size = 50\n",
    "y_size = 2\n",
    "\n",
    "num_epochs = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "db737f61",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Model, self).__init__()\n",
    "        self.Embedder = Embedder()\n",
    "        self.VMD = VMD(self)\n",
    "        self.ATA = ATA(self)\n",
    "    \n",
    "    \n",
    "    def forward(self, X, Y):\n",
    "        \"\"\"\n",
    "            \n",
    "        \"\"\"\n",
    "        \n",
    "        X = self.Embedder(X)\n",
    "        self.VMD(X, Y)\n",
    "        self.ATA(Y)\n",
    "#         print(\"X\", X.shape)\n",
    "#         print(\"kl\", self.kl.shape)\n",
    "#         print(\"g\", self.g.shape)\n",
    "#         print(\"y\", self.y.shape)\n",
    "        # result = something\n",
    "#         return X  \n",
    "    \n",
    "    \n",
    "    def get_z_and_z_distr(self, arg, is_prior):\n",
    "        mean = nn.Linear(arg.size(-1), vmd_hidden_size)(arg)\n",
    "        stddev = nn.Linear(arg.size(-1), vmd_hidden_size)(arg)      \n",
    "        stddev = torch.sqrt(torch.exp(stddev))\n",
    "        epsilon = torch.randn(vmd_hidden_size)\n",
    "        \n",
    "        z = mean if is_prior else mean + torch.mul(epsilon, stddev)\n",
    "        z_pdf = ds.normal.Normal(loc=mean, scale=stddev)\n",
    "        return z, z_pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c56590d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Embedder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Embedder, self).__init__()\n",
    "        self.bi_gru = nn.GRU(word_embed_size, embedder_hidden_size, num_layers=gru_num_layers, batch_first=True, bidirectional=True)\n",
    "        \n",
    "\n",
    "    def forward(self, X):\n",
    "        \"\"\"\n",
    "            X: window_size (for speaker's history) * max_words_in_a_speech * input_size\n",
    "            \n",
    "        \"\"\"\n",
    "#         X = get_glove_padded_seq(X)\n",
    "        h_0 = torch.randn(2*gru_num_layers, window_size, embedder_hidden_size) # multiplied by 2 because bidirectional\n",
    "        _, h_n = self.bi_gru(X, h_0)\n",
    "        h_f = h_n[0, :, :] \n",
    "        h_b = h_n[1, :, :]\n",
    "        msg_embed = (h_f + h_b) / 2\n",
    "        return msg_embed\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7a5cf5b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class VMD(nn.Module):\n",
    "    def __init__(self, model):\n",
    "        super(VMD, self).__init__()\n",
    "#         self.input_dropout = nn.Dropout(p=dropout_vmd_in)\n",
    "        self.model = model    \n",
    "        self.gru = nn.GRU(embedder_hidden_size, vmd_hidden_size, num_layers=gru_num_layers, bidirectional=False)\n",
    "        \n",
    "        \n",
    "    def forward(self, X, Y):\n",
    "#         X = self.input_dropout(X)\n",
    "        h_0 = torch.randn(gru_num_layers, vmd_hidden_size) \n",
    "        h_s, _ = self.gru(X, h_0) # h_s: window_size * vmd_hidden_size\n",
    "        \n",
    "        z_prior = []\n",
    "        z_post = []\n",
    "        kl = []\n",
    "        z_post_t_minus_1 = torch.randn(vmd_hidden_size)\n",
    "        for t in range(window_size):\n",
    "            h_z_prior_t = nn.Linear(embedder_hidden_size+2*vmd_hidden_size, vmd_hidden_size)(\n",
    "                torch.cat([X[t], h_s[t], z_post_t_minus_1])\n",
    "            )\n",
    "            h_z_prior_t = nn.Tanh()(h_z_prior_t)\n",
    "\n",
    "            h_z_post_t = nn.Linear(embedder_hidden_size+2*vmd_hidden_size+y_size, vmd_hidden_size)(\n",
    "                torch.cat([X[t], h_s[t], Y[t], z_post_t_minus_1])\n",
    "            )\n",
    "            h_z_post_t = nn.Tanh()(h_z_post_t)\n",
    "            \n",
    "            z_prior_t, z_prior_t_pdf = self.model.get_z_and_z_distr(h_z_prior_t, is_prior=True)\n",
    "            z_post_t, z_post_t_pdf = self.model.get_z_and_z_distr(h_z_post_t, is_prior=False)\n",
    "            z_post_t_minus_1 = z_post_t\n",
    "            \n",
    "            kl_t = ds.kl.kl_divergence(z_prior_t_pdf, z_post_t_pdf)\n",
    "            \n",
    "            z_prior.append(z_prior_t)\n",
    "            z_post.append(z_post_t)\n",
    "            kl.append(kl_t)\n",
    "        \n",
    "        z_prior = torch.stack(z_prior) # window_size * vmd_hidden_size\n",
    "        z_post = torch.stack(z_post) # window_size * vmd_hidden_size\n",
    "        self.model.kl = torch.stack(kl).sum(dim=1) # window_size\n",
    "        \n",
    "        self.model.g = nn.Linear(2*vmd_hidden_size, g_size)(\n",
    "            torch.cat([h_s, z_post],dim=1) # TODO: check if X is also to be concatenated as in Eqn 21\n",
    "        )        \n",
    "        self.model.g = nn.Tanh()(self.model.g) #\n",
    "        \n",
    "        y = nn.Linear(g_size, y_size)(self.model.g)\n",
    "        self.model.y = nn.Softmax(dim=1)(y)\n",
    "#         print(\"y:\", self.model.y)\n",
    "\n",
    "        self.model.g_T = self.model.g[-1, :] \n",
    "        # TODO: 1. will g_T be different during training and evaluation?\n",
    "        # TODO: 2. is g_T definitely what you think it is?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff7e57df",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7d3dbf72",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ATA(nn.Module):\n",
    "    def __init__(self, model):\n",
    "        super(ATA, self).__init__()\n",
    "        self.model = model\n",
    "        self.alpha = 0.5\n",
    "        \n",
    "        \n",
    "    def forward(self, Y):\n",
    "        linear_i = nn.Linear(g_size, g_size, bias=False)(self.model.g)\n",
    "        linear_i = nn.Tanh()(linear_i) # (window_size, g_size)\n",
    "        w_i = nn.init.xavier_normal_(torch.zeros((g_size, 1))) # (g_size, 1)\n",
    "        v_i = linear_i @ w_i # (window_size, 1)\n",
    "        \n",
    "        linear_d = nn.Linear(g_size, g_size, bias=False)(self.model.g)\n",
    "        linear_d = nn.Tanh()(linear_d)\n",
    "        g_T = self.model.g_T[:, None]\n",
    "        v_d = linear_d @ g_T\n",
    "        \n",
    "        aux_score = torch.mul(v_i, v_d)\n",
    "        aux_score[-1, :] = np.NINF\n",
    "        \n",
    "        v_starred = nn.Softmax(dim=0)(aux_score)\n",
    "        self.model.v_starred = torch.where(torch.isnan(v_starred), torch.tensor(0, dtype=torch.float32), v_starred)\n",
    "        \n",
    "        att_c = self.model.v_starred.T @ self.model.y\n",
    "#         print(att_c.shape, self.model.g_T.shape)\n",
    "        self.model.y_T = nn.Linear(y_size+g_size, y_size)(torch.cat([torch.squeeze(att_c), self.model.g_T]))\n",
    "        self.model.y_T = nn.Softmax(dim=0)(self.model.y_T)  \n",
    "#         print(\"y_T:\", self.model.y_T.shape)\n",
    "        \n",
    "        self.calculate_loss(Y)\n",
    "        \n",
    "        \n",
    "    def calculate_loss(self, Y):\n",
    "#         print(self.model.v_starred)\n",
    "        v_aux = self.alpha * self.model.v_starred\n",
    "        likelihood_aux = torch.sum(torch.mul(Y, torch.log(self.model.y)), dim=1)\n",
    "        \n",
    "        kl_lambda = self.get_kl_lambda()\n",
    "        obj_aux = likelihood_aux - kl_lambda * self.model.kl\n",
    "        \n",
    "        y_T_orig = Y[-1, :]\n",
    "        likelihood_T = torch.sum(torch.mul(y_T_orig, torch.log(self.model.y_T)))\n",
    "        \n",
    "        kl_T = self.model.kl[-1]\n",
    "        obj_T = likelihood_T - kl_lambda * kl_T\n",
    "        \n",
    "        self.model.loss = obj_T + torch.sum(torch.mul(obj_aux, v_aux))\n",
    "        \n",
    "        \n",
    "    def get_kl_lambda(self):\n",
    "        # TODO: implement KL annealing\n",
    "        return 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ab5818f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40ce2d5e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bc9348f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cbb48f2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "219b5443",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "dee512e0",
   "metadata": {},
   "source": [
    "# Prepare train data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6df317cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"dataset/ParlVote/ParlVote_concat.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "795cc2c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# speakers[speaker_id: int] = list of tuples (debate_id, speech, vote)\n",
    "speakers = defaultdict(lambda: [])\n",
    "for idx, row in data.iterrows():\n",
    "    speakers[row[\"speaker_id\"]].append([row[\"debate_id\"], row[\"speech\"], row[\"vote\"]])\n",
    "        \n",
    "for k, v in speakers.items():\n",
    "    speakers[k] = sorted(v)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94ec6536",
   "metadata": {},
   "source": [
    "## Analysis of speaker sequence length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6f3bf409",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "284\n"
     ]
    }
   ],
   "source": [
    "mx = 0\n",
    "for usid in data.speaker_id.unique():\n",
    "    mx = max(mx, len(speakers[usid]))\n",
    "print(mx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cd8693da",
   "metadata": {},
   "outputs": [],
   "source": [
    "speaker_history_lens = []\n",
    "for sid, each in speakers.items():\n",
    "    speaker_history_lens.append(len(each)) \n",
    "speaker_history_lens.sort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f5ab5efa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    1346.000000\n",
       "mean       24.859584\n",
       "std        26.420400\n",
       "min         1.000000\n",
       "25%         8.000000\n",
       "50%        16.000000\n",
       "75%        32.000000\n",
       "max       284.000000\n",
       "dtype: float64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shl = pd.Series(speaker_history_lens)\n",
    "shl.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "285925b1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "90.04457652303121"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(len(list(filter(lambda x: x >= 4, speaker_history_lens))) / len(speaker_history_lens)) * 100"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64cd3ba6",
   "metadata": {},
   "source": [
    "- The above cell shows 90% speakers have at least *window_size*=4 speeches\n",
    "- If we use all data, we need to pad speeches that have (< *window_size*=4) speeches\n",
    "- Decision: Drop these 10% speakers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a9eef339",
   "metadata": {},
   "outputs": [],
   "source": [
    "speakers = dict(filter(lambda val: len(val[1]) >= 4, speakers.items()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0efb9289",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "90.04457652303121"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "100 * (len(speakers) / len(speaker_history_lens))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48bdfbf5",
   "metadata": {},
   "source": [
    "## Download Glove-100d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2983bb03",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! wget -r -nc https://nlp.stanford.edu/data/glove.6B.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "22ee51f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !unzip nlp.stanford.edu/data/glove.6B.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d3df5538",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! head -n1 glove.6B.100d.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "bbb4a9c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "embeds = dict()\n",
    "for line in open(\"nlp.stanford.edu/data/glove.6B.100d.txt\", \"r\"):\n",
    "    line = line.split()\n",
    "    embeds[line[0]] = torch.tensor(list(map(float, line[1:])), dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3d0c5552",
   "metadata": {},
   "outputs": [],
   "source": [
    "# glove_vocab = set()\n",
    "# for f in open(\"nlp.stanford.edu/data/glove.6B.100d.txt\", \"r\"):\n",
    "#     glove_vocab.add(f.split()[0])\n",
    "# print(len(glove_vocab))\n",
    "\n",
    "# del glove_vocab"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f60ca37",
   "metadata": {},
   "source": [
    "## Preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "998c06dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import TweetTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "65c9093d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "# import nltk\n",
    "# nltk.download('punkt')\n",
    "# nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "bca1c466",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(s: str):\n",
    "    \n",
    "    # Lowercasing\n",
    "    s = s.lower()\n",
    "    \n",
    "    # Tokenization\n",
    "    ttk = TweetTokenizer()\n",
    "    tokens = ttk.tokenize(s)\n",
    "#     tokens = word_tokenize(s)\n",
    "    \n",
    "    # Stopwords removal\n",
    "    tokens = [w for w in tokens if not w in stopwords.words('english')]\n",
    "    \n",
    "#     # Stemming\n",
    "#     ps = nltk.PorterStemmer()\n",
    "#     tokens = [ps.stem(w) for w in tokens]\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "9cb28122",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# %%timeit\n",
    "# embed_keys = set(embeds.keys())\n",
    "# ans = 0\n",
    "# i = 0\n",
    "# sids = speakers.keys()\n",
    "# for sid in sids:\n",
    "    \n",
    "#     s = speakers[sid][0][1]\n",
    "#     pre = preprocess(s)\n",
    "#     ans += len(set(pre).difference((set(pre).intersection(embed_keys))))\n",
    "    \n",
    "#     print(\"i\", i, \" done:\", ans)\n",
    "#     i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b57c95f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# embeds['abhorrent']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "3c16bb97",
   "metadata": {},
   "outputs": [],
   "source": [
    "# input1 = embeds[\"drank\"]\n",
    "# input2 = embeds[\"drunk\"]\n",
    "# cos = nn.CosineSimilarity(dim=0)\n",
    "# output = cos(input1, input2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad8b5e30",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2dae4822",
   "metadata": {},
   "source": [
    "## Create PaddedTensor for input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "073d442b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn.utils.rnn import pad_sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "be61fce0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_X_Y_padded_tensors(debates):\n",
    "        \"\"\"\n",
    "            X: window_size * max_seq_len * word_embed_size \n",
    "            Y: window_size\n",
    "        \"\"\"\n",
    "        X = []\n",
    "        Y = []\n",
    "        max_tokens = 0\n",
    "        for _, speech, vote in debates:\n",
    "            tokens = preprocess(speech)\n",
    "#             print(\"len preprocessed speech:\", len(tokens))\n",
    "            X.append(torch.stack([embeds.get(token, torch.randn(word_embed_size)) for token in tokens]))\n",
    "            y = torch.zeros(2)\n",
    "            y[vote] = 1. # y = [0, 1] if vote=1 else [1, 0]\n",
    "            Y.append(y)\n",
    "        \n",
    "        X = pad_sequence(X, batch_first=True)\n",
    "        return X, torch.stack(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "dc16200a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "6767ebd5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Embedder(\n",
       "  (bi_gru): GRU(100, 100, batch_first=True, bidirectional=True)\n",
       ")"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.Embedder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "93a09fed",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "c3ee6947",
   "metadata": {},
   "outputs": [],
   "source": [
    "freq = [len(v) for k, v in speakers.items()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "79c12eb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "freq_sum = torch.tensor(freq).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "30788fd2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "33181"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(freq_sum.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14091e0b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "734e35d8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "837"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum_ = 0\n",
    "ans = 0\n",
    "freq_sum = torch.tensor(freq).sum().item()\n",
    "for i in range(len(freq)-1, -1, -1):\n",
    "    if sum_ + (freq[i]) > 0.2 * freq_sum:\n",
    "        break\n",
    "    sum_ += (freq[i])\n",
    "    ans = i\n",
    "ans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "c7275b32",
   "metadata": {},
   "outputs": [
    {
     "ename": "RecursionError",
     "evalue": "maximum recursion depth exceeded while calling a Python object",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRecursionError\u001b[0m                            Traceback (most recent call last)",
      "Input \u001b[0;32mIn [39]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstate_dict\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/myProjects/rawnit_sawhney_defi_task/venv/lib/python3.8/site-packages/torch/nn/modules/module.py:1318\u001b[0m, in \u001b[0;36mModule.state_dict\u001b[0;34m(self, destination, prefix, keep_vars)\u001b[0m\n\u001b[1;32m   1316\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m name, module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_modules\u001b[38;5;241m.\u001b[39mitems():\n\u001b[1;32m   1317\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m module \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1318\u001b[0m         \u001b[43mmodule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstate_dict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdestination\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprefix\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m.\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkeep_vars\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkeep_vars\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1319\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m hook \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_state_dict_hooks\u001b[38;5;241m.\u001b[39mvalues():\n\u001b[1;32m   1320\u001b[0m     hook_result \u001b[38;5;241m=\u001b[39m hook(\u001b[38;5;28mself\u001b[39m, destination, prefix, local_metadata)\n",
      "File \u001b[0;32m~/myProjects/rawnit_sawhney_defi_task/venv/lib/python3.8/site-packages/torch/nn/modules/module.py:1318\u001b[0m, in \u001b[0;36mModule.state_dict\u001b[0;34m(self, destination, prefix, keep_vars)\u001b[0m\n\u001b[1;32m   1316\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m name, module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_modules\u001b[38;5;241m.\u001b[39mitems():\n\u001b[1;32m   1317\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m module \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1318\u001b[0m         \u001b[43mmodule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstate_dict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdestination\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprefix\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m.\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkeep_vars\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkeep_vars\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1319\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m hook \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_state_dict_hooks\u001b[38;5;241m.\u001b[39mvalues():\n\u001b[1;32m   1320\u001b[0m     hook_result \u001b[38;5;241m=\u001b[39m hook(\u001b[38;5;28mself\u001b[39m, destination, prefix, local_metadata)\n",
      "    \u001b[0;31m[... skipping similar frames: Module.state_dict at line 1318 (9968 times)]\u001b[0m\n",
      "File \u001b[0;32m~/myProjects/rawnit_sawhney_defi_task/venv/lib/python3.8/site-packages/torch/nn/modules/module.py:1318\u001b[0m, in \u001b[0;36mModule.state_dict\u001b[0;34m(self, destination, prefix, keep_vars)\u001b[0m\n\u001b[1;32m   1316\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m name, module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_modules\u001b[38;5;241m.\u001b[39mitems():\n\u001b[1;32m   1317\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m module \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1318\u001b[0m         \u001b[43mmodule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstate_dict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdestination\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprefix\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m.\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkeep_vars\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkeep_vars\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1319\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m hook \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_state_dict_hooks\u001b[38;5;241m.\u001b[39mvalues():\n\u001b[1;32m   1320\u001b[0m     hook_result \u001b[38;5;241m=\u001b[39m hook(\u001b[38;5;28mself\u001b[39m, destination, prefix, local_metadata)\n",
      "File \u001b[0;32m~/myProjects/rawnit_sawhney_defi_task/venv/lib/python3.8/site-packages/torch/nn/modules/module.py:1315\u001b[0m, in \u001b[0;36mModule.state_dict\u001b[0;34m(self, destination, prefix, keep_vars)\u001b[0m\n\u001b[1;32m   1313\u001b[0m     destination\u001b[38;5;241m.\u001b[39m_metadata \u001b[38;5;241m=\u001b[39m OrderedDict()\n\u001b[1;32m   1314\u001b[0m destination\u001b[38;5;241m.\u001b[39m_metadata[prefix[:\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]] \u001b[38;5;241m=\u001b[39m local_metadata \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mdict\u001b[39m(version\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_version)\n\u001b[0;32m-> 1315\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_save_to_state_dict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdestination\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprefix\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkeep_vars\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1316\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m name, module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_modules\u001b[38;5;241m.\u001b[39mitems():\n\u001b[1;32m   1317\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m module \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/myProjects/rawnit_sawhney_defi_task/venv/lib/python3.8/site-packages/torch/nn/modules/module.py:1270\u001b[0m, in \u001b[0;36mModule._save_to_state_dict\u001b[0;34m(self, destination, prefix, keep_vars)\u001b[0m\n\u001b[1;32m   1257\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_save_to_state_dict\u001b[39m(\u001b[38;5;28mself\u001b[39m, destination, prefix, keep_vars):\n\u001b[1;32m   1258\u001b[0m     \u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"Saves module state to `destination` dictionary, containing a state\u001b[39;00m\n\u001b[1;32m   1259\u001b[0m \u001b[38;5;124;03m    of the module, but not its descendants. This is called on every\u001b[39;00m\n\u001b[1;32m   1260\u001b[0m \u001b[38;5;124;03m    submodule in :meth:`~torch.nn.Module.state_dict`.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1268\u001b[0m \u001b[38;5;124;03m            module\u001b[39;00m\n\u001b[1;32m   1269\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 1270\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m name, param \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_parameters\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mitems\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[1;32m   1271\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m param \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   1272\u001b[0m             destination[prefix \u001b[38;5;241m+\u001b[39m name] \u001b[38;5;241m=\u001b[39m param \u001b[38;5;28;01mif\u001b[39;00m keep_vars \u001b[38;5;28;01melse\u001b[39;00m param\u001b[38;5;241m.\u001b[39mdetach()\n",
      "\u001b[0;31mRecursionError\u001b[0m: maximum recursion depth exceeded while calling a Python object"
     ]
    }
   ],
   "source": [
    "model.state_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "14c23c6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Speaker num: 0 \t done: 5 \t perc: 0.01883608088966577 \tloss: tensor(-79.5806, grad_fn=<AddBackward0>) \n",
      "--------------------------------------------------\n",
      "\n"
     ]
    },
    {
     "ename": "RecursionError",
     "evalue": "maximum recursion depth exceeded while calling a Python object",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRecursionError\u001b[0m                            Traceback (most recent call last)",
      "Input \u001b[0;32mIn [38]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mget_ipython\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_cell_magic\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtimeit\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mfor epoch in range(num_epochs):\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m    scnt = 0\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m    done_cnt = 0\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m    loss_batch = 0\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m    for speaker_num, (speaker_id, debates) in enumerate(speakers.items()):\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m        for i in range(window_size, len(debates)+1):\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m            X, Y = get_X_Y_padded_tensors(debates[i-window_size: i]) \u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m            model(X, Y)\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m            loss_batch += model.loss\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m            \u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m            optimizer.zero_grad()\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m            model.loss.backward()\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m            optimizer.step()\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m            \u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m            done_cnt += 1\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m            if done_cnt\u001b[39;49m\u001b[38;5;124;43m%\u001b[39;49m\u001b[38;5;124;43m5==0:\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m                print(\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mSpeaker num:\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m, speaker_num, \u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;130;43;01m\\\\\u001b[39;49;00m\u001b[38;5;124;43mt\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m, \u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mdone:\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m, done_cnt, \u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;130;43;01m\\\\\u001b[39;49;00m\u001b[38;5;124;43mt\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m, \u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mperc:\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m, 100*(done_cnt/(0.8*freq_sum)), \u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;130;43;01m\\\\\u001b[39;49;00m\u001b[38;5;124;43mtloss:\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m, loss_batch, \u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;130;43;01m\\\\\u001b[39;49;00m\u001b[38;5;124;43mn\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m+\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m-\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m*50+\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;130;43;01m\\\\\u001b[39;49;00m\u001b[38;5;124;43mn\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m)\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m                loss_batch = 0\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m                \u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m            if done_cnt\u001b[39;49m\u001b[38;5;124;43m%\u001b[39;49m\u001b[38;5;124;43m5 == 0:\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m                torch.save(model.state_dict(), \u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfinal_model.pt\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m)\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m        if scnt > ans:\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m            break\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m        scnt += 1\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/myProjects/rawnit_sawhney_defi_task/venv/lib/python3.8/site-packages/IPython/core/interactiveshell.py:2357\u001b[0m, in \u001b[0;36mInteractiveShell.run_cell_magic\u001b[0;34m(self, magic_name, line, cell)\u001b[0m\n\u001b[1;32m   2355\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbuiltin_trap:\n\u001b[1;32m   2356\u001b[0m     args \u001b[38;5;241m=\u001b[39m (magic_arg_s, cell)\n\u001b[0;32m-> 2357\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2358\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[0;32m~/myProjects/rawnit_sawhney_defi_task/venv/lib/python3.8/site-packages/IPython/core/magics/execution.py:1162\u001b[0m, in \u001b[0;36mExecutionMagics.timeit\u001b[0;34m(self, line, cell, local_ns)\u001b[0m\n\u001b[1;32m   1160\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m index \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m10\u001b[39m):\n\u001b[1;32m   1161\u001b[0m     number \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m10\u001b[39m \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m index\n\u001b[0;32m-> 1162\u001b[0m     time_number \u001b[38;5;241m=\u001b[39m \u001b[43mtimer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtimeit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnumber\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1163\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m time_number \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.2\u001b[39m:\n\u001b[1;32m   1164\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[0;32m~/myProjects/rawnit_sawhney_defi_task/venv/lib/python3.8/site-packages/IPython/core/magics/execution.py:156\u001b[0m, in \u001b[0;36mTimer.timeit\u001b[0;34m(self, number)\u001b[0m\n\u001b[1;32m    154\u001b[0m gc\u001b[38;5;241m.\u001b[39mdisable()\n\u001b[1;32m    155\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 156\u001b[0m     timing \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minner\u001b[49m\u001b[43m(\u001b[49m\u001b[43mit\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtimer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    157\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    158\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m gcold:\n",
      "File \u001b[0;32m<magic-timeit>:21\u001b[0m, in \u001b[0;36minner\u001b[0;34m(_it, _timer)\u001b[0m\n",
      "File \u001b[0;32m~/myProjects/rawnit_sawhney_defi_task/venv/lib/python3.8/site-packages/torch/nn/modules/module.py:1318\u001b[0m, in \u001b[0;36mModule.state_dict\u001b[0;34m(self, destination, prefix, keep_vars)\u001b[0m\n\u001b[1;32m   1316\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m name, module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_modules\u001b[38;5;241m.\u001b[39mitems():\n\u001b[1;32m   1317\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m module \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1318\u001b[0m         \u001b[43mmodule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstate_dict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdestination\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprefix\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m.\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkeep_vars\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkeep_vars\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1319\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m hook \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_state_dict_hooks\u001b[38;5;241m.\u001b[39mvalues():\n\u001b[1;32m   1320\u001b[0m     hook_result \u001b[38;5;241m=\u001b[39m hook(\u001b[38;5;28mself\u001b[39m, destination, prefix, local_metadata)\n",
      "File \u001b[0;32m~/myProjects/rawnit_sawhney_defi_task/venv/lib/python3.8/site-packages/torch/nn/modules/module.py:1318\u001b[0m, in \u001b[0;36mModule.state_dict\u001b[0;34m(self, destination, prefix, keep_vars)\u001b[0m\n\u001b[1;32m   1316\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m name, module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_modules\u001b[38;5;241m.\u001b[39mitems():\n\u001b[1;32m   1317\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m module \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1318\u001b[0m         \u001b[43mmodule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstate_dict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdestination\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprefix\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m.\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkeep_vars\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkeep_vars\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1319\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m hook \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_state_dict_hooks\u001b[38;5;241m.\u001b[39mvalues():\n\u001b[1;32m   1320\u001b[0m     hook_result \u001b[38;5;241m=\u001b[39m hook(\u001b[38;5;28mself\u001b[39m, destination, prefix, local_metadata)\n",
      "    \u001b[0;31m[... skipping similar frames: Module.state_dict at line 1318 (9964 times)]\u001b[0m\n",
      "File \u001b[0;32m~/myProjects/rawnit_sawhney_defi_task/venv/lib/python3.8/site-packages/torch/nn/modules/module.py:1318\u001b[0m, in \u001b[0;36mModule.state_dict\u001b[0;34m(self, destination, prefix, keep_vars)\u001b[0m\n\u001b[1;32m   1316\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m name, module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_modules\u001b[38;5;241m.\u001b[39mitems():\n\u001b[1;32m   1317\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m module \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1318\u001b[0m         \u001b[43mmodule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstate_dict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdestination\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprefix\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m.\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkeep_vars\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkeep_vars\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1319\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m hook \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_state_dict_hooks\u001b[38;5;241m.\u001b[39mvalues():\n\u001b[1;32m   1320\u001b[0m     hook_result \u001b[38;5;241m=\u001b[39m hook(\u001b[38;5;28mself\u001b[39m, destination, prefix, local_metadata)\n",
      "File \u001b[0;32m~/myProjects/rawnit_sawhney_defi_task/venv/lib/python3.8/site-packages/torch/nn/modules/module.py:1315\u001b[0m, in \u001b[0;36mModule.state_dict\u001b[0;34m(self, destination, prefix, keep_vars)\u001b[0m\n\u001b[1;32m   1313\u001b[0m     destination\u001b[38;5;241m.\u001b[39m_metadata \u001b[38;5;241m=\u001b[39m OrderedDict()\n\u001b[1;32m   1314\u001b[0m destination\u001b[38;5;241m.\u001b[39m_metadata[prefix[:\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]] \u001b[38;5;241m=\u001b[39m local_metadata \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mdict\u001b[39m(version\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_version)\n\u001b[0;32m-> 1315\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_save_to_state_dict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdestination\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprefix\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkeep_vars\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1316\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m name, module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_modules\u001b[38;5;241m.\u001b[39mitems():\n\u001b[1;32m   1317\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m module \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/myProjects/rawnit_sawhney_defi_task/venv/lib/python3.8/site-packages/torch/nn/modules/module.py:1270\u001b[0m, in \u001b[0;36mModule._save_to_state_dict\u001b[0;34m(self, destination, prefix, keep_vars)\u001b[0m\n\u001b[1;32m   1257\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_save_to_state_dict\u001b[39m(\u001b[38;5;28mself\u001b[39m, destination, prefix, keep_vars):\n\u001b[1;32m   1258\u001b[0m     \u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"Saves module state to `destination` dictionary, containing a state\u001b[39;00m\n\u001b[1;32m   1259\u001b[0m \u001b[38;5;124;03m    of the module, but not its descendants. This is called on every\u001b[39;00m\n\u001b[1;32m   1260\u001b[0m \u001b[38;5;124;03m    submodule in :meth:`~torch.nn.Module.state_dict`.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1268\u001b[0m \u001b[38;5;124;03m            module\u001b[39;00m\n\u001b[1;32m   1269\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 1270\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m name, param \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_parameters\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mitems\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[1;32m   1271\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m param \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   1272\u001b[0m             destination[prefix \u001b[38;5;241m+\u001b[39m name] \u001b[38;5;241m=\u001b[39m param \u001b[38;5;28;01mif\u001b[39;00m keep_vars \u001b[38;5;28;01melse\u001b[39;00m param\u001b[38;5;241m.\u001b[39mdetach()\n",
      "\u001b[0;31mRecursionError\u001b[0m: maximum recursion depth exceeded while calling a Python object"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "for epoch in range(num_epochs):\n",
    "    scnt = 0\n",
    "    done_cnt = 0\n",
    "    loss_batch = 0\n",
    "    for speaker_num, (speaker_id, debates) in enumerate(speakers.items()):\n",
    "        for i in range(window_size, len(debates)+1):\n",
    "            X, Y = get_X_Y_padded_tensors(debates[i-window_size: i]) \n",
    "            model(X, Y)\n",
    "            loss_batch += model.loss\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            model.loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            done_cnt += 1\n",
    "            if done_cnt%5==0:\n",
    "                print(\"Speaker num:\", speaker_num, \"\\t\", \"done:\", done_cnt, \"\\t\", \"perc:\", 100*(done_cnt/(0.8*freq_sum)), \"\\tloss:\", loss_batch, \"\\n\"+\"-\"*50+\"\\n\")\n",
    "                loss_batch = 0\n",
    "                \n",
    "            if done_cnt%5 == 0:\n",
    "                torch.save(model.state_dict(), \"final_model.pt\")\n",
    "\n",
    "        if scnt > ans:\n",
    "            break\n",
    "        scnt += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e5a038ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.setrecursionlimit(10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba9e4a99",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
